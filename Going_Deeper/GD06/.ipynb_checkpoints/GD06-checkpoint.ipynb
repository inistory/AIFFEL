{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "functional-eight",
   "metadata": {},
   "source": [
    "# GD06 임베딩 내 편향성 알아보기\n",
    "지금까지 우리는 영화 시놉시스 코퍼스를 가지고 영화 구분과 영화 장르 간에 내재된 편향성을 측정하는 작업을 진행해 보았습니다. 어느 정도는 우리의 상식과 일치하는 편향성이 측정되었을 것입니다.\n",
    "\n",
    "이번에는 모든 장르에 대해 영화 구분과의 편향성 정도를 측정해 보겠습니다. 대부분의 과정은 이전 스텝에서 이미 진행한 내용을 참고해서 동일하게 진행 가능할 것입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "earned-tours",
   "metadata": {},
   "source": [
    "## STEP 1. 형태소 분석기를 이용하여 품사가 명사인 경우 해당 단어를 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "passive-haiti",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 4\r\n",
      "-rw-r--r-- 1 root root 1429 Dec 28 16:11 GD06.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/aiffel/weat\n",
    "!ln -s ~/data/* ~/aiffel/weat/\n",
    "!cd ~/aiffel/weat\n",
    "!ls -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "invalid-formation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in /opt/conda/lib/python3.7/site-packages (4.0.1)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (4.1.2)\n",
      "Requirement already satisfied: scipy>=0.18.1 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /opt/conda/lib/python3.7/site-packages (from gensim) (1.19.5)\n",
      "\u001b[33mWARNING: You are using pip version 20.3.3; however, version 21.3.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rotary-consideration",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KeyedVectors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-22d0c67266ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mw2v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'KeyedVectors' is not defined"
     ]
    }
   ],
   "source": [
    "w2v = KeyedVectors.load_word2vec_format(model_dir, binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "round-montgomery",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "data_dir = '~/aiffel/weat' \n",
    "model_dir = os.path.join(data_dir, 'GoogleNews-vectors-negative300.bin')\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "# 50만개의 단어만 활용합니다. 메모리가 충분하다면 limit 파라미터값을 생략하여 300만개를 모두 활용할 수 있습니다. \n",
    "w2v = KeyedVectors.load_word2vec_format(model_dir, binary=True, limit=500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "featured-ottawa",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "julian-amber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(len(w2v.vocab))   # Gensim 3.X 버전까지는 w2v.vocab을 직접 접근할 수 있습니다. \n",
    "print(len(w2v.index_to_key))   # Gensim 4.0부터는 index_to_key를 활용해 vocab size를 알 수 있습니다. \n",
    "print(len(w2v['I']))                    # 혹은 단어를 key로 직접 vector를 얻을 수 있습니다. \n",
    "print(w2v.vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satellite-martial",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v['happy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-preparation",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['happy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fifteen-technician",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['family'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inner-logic",
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v.most_similar(positive=['school'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "under-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = ['science', 'technology', 'physics', 'chemistry', 'Einstein', 'NASA', 'experiment', 'astronomy']\n",
    "target_Y = ['poetry', 'art', 'Shakespeare', 'dance', 'literature', 'novel', 'symphony', 'drama']\n",
    "attribute_A = ['brother', 'father', 'uncle', 'grandfather', 'son', 'he', 'his', 'him']\n",
    "attribute_B = ['sister', 'mother', 'aunt', 'grandmother', 'daughter', 'she', 'hers', 'her']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-lindsay",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['junk', 'canned', 'convenience', 'frozen', 'fast']\n",
    "attribute_B = ['health', 'beneficial', 'good', 'nourishing', 'nutritious']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = ['pizza', 'coke', 'hamburger', 'ham', 'ramen', 'icecream', 'candy']\n",
    "target_Y = ['salad', 'fruit', 'vegetable', 'herb', 'root', 'greens', 'wholesome']\n",
    "attribute_A = ['book', 'essay', 'dictionary', 'magazine', 'novel']\n",
    "attribute_B = ['news', 'report', 'statement', 'broadcast', 'word']\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compressed-competition",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_X = [# TODO : 입력해 주세요!!]\n",
    "target_Y = [# TODO : 입력해 주세요!!]\n",
    "attribute_A = [# TODO : 입력해 주세요!!]\n",
    "attribute_B = [# TODO : 입력해 주세요!!]\n",
    "\n",
    "X = np.array([w2v[word] for word in target_X])\n",
    "Y = np.array([w2v[word] for word in target_Y])\n",
    "A = np.array([w2v[word] for word in attribute_A])\n",
    "B = np.array([w2v[word] for word in attribute_B])\n",
    "\n",
    "weat_score(X, Y, A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#메모리를 다시 비워줍시다.\n",
    "del w2v\n",
    "print(\"삭제 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-defensive",
   "metadata": {},
   "source": [
    "## STEP 2. 추출된 결과로 embedding model 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-suspect",
   "metadata": {},
   "source": [
    "## STEP 3. target, attribute 단어 셋 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "great-possible",
   "metadata": {},
   "source": [
    "## STEP 4. WEAT score 계산과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brutal-syracuse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
