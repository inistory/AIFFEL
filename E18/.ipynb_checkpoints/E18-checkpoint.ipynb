{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "identical-response",
   "metadata": {},
   "source": [
    "# E18 다양한 OCR 모델 비교하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "hairy-canyon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "%matplotlib inline\n",
    "\n",
    "import keras_ocr\n",
    "\n",
    "import pytesseract\n",
    "from PIL import Image\n",
    "from pytesseract import Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-winter",
   "metadata": {},
   "source": [
    "## Step1. 검증용 데이터셋 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "lesbian-triangle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_dir = '/aiffel/AIFFEL/E18/img/'\n",
    "\n",
    "images = glob(work_dir+'*.jpeg')\n",
    "images.sort()\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accomplished-stranger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x1440 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "\n",
    "for idx, im in enumerate(images):\n",
    "    plt.subplot(6, 3, idx+1)\n",
    "    im = img.imread(im)\n",
    "    plt.imshow(im)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "political-significance",
   "metadata": {},
   "source": [
    "##  Step2. Google OCR API, keras-ocr, Tesseract로 테스트 진행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-process",
   "metadata": {},
   "source": [
    "### Google OCR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stopped-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    from google.cloud import vision\n",
    "    import io\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "        \n",
    "    image = vision.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "       print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "    vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                 for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "    print('bounds: {}'.format(','.join(vertices)))\n",
    "\n",
    "    if response.error.message:\n",
    "        raise Exception(\n",
    "            '{}\\nFor more info on error messages, check: '\n",
    "            'https://cloud.google.com/apis/design/errors'.format(\n",
    "                response.error.message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "blank-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "for im in images:\n",
    "    detect_text(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-denver",
   "metadata": {},
   "source": [
    "### Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_word_regions(idx, image_path='./images/sample.png', output_path='./output'):\n",
    "    if not os.path.exists(output_path):\n",
    "        os.mkdir(output_path)\n",
    "    custom_oem_psm_config = r'--oem 3 --psm 3'\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    recognized_data = pytesseract.image_to_data(\n",
    "        image, lang='eng',    # 한국어라면 lang='kor'\n",
    "        config=custom_oem_psm_config,\n",
    "        output_type=Output.DICT\n",
    "    )\n",
    "    \n",
    "    top_level = max(recognized_data['level'])\n",
    "    index = 0\n",
    "    cropped_image_path_list = []\n",
    "    for i in range(len(recognized_data['level'])):\n",
    "        level = recognized_data['level'][i]\n",
    "        \n",
    "        if level == top_level:\n",
    "            left = recognized_data['left'][i]\n",
    "            top = recognized_data['top'][i]\n",
    "            width = recognized_data['width'][i]\n",
    "            height = recognized_data['height'][i]\n",
    "            \n",
    "            output_img_path = os.path.join(output_path, f\"{str(index).zfill(4)}.png\")\n",
    "            cropped_image = image.crop((\n",
    "                left,\n",
    "                top,\n",
    "                left+width,\n",
    "                top+height\n",
    "            ))\n",
    "            cropped_image.save(output_img_path)\n",
    "            cropped_image_path_list.append(output_img_path)\n",
    "            index += 1\n",
    "    return cropped_image_path_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "working-night",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cropped_image_path_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-c113de3655ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcr_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcropped_image_path_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrecognize_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcr_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cropped_image_path_list' is not defined"
     ]
    }
   ],
   "source": [
    "for cr_path in cropped_image_path_list:\n",
    "    recognize_images(cr_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "authorized-software",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bearing-command",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-peripheral",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outer-enterprise",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "touched-accordance",
   "metadata": {},
   "source": [
    "##  Step3. 테스트 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "senior-desire",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "im = img.imread(images[7])\n",
    "plt.imshow(im)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "integral-tomato",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize_images(cropped_image_path_list[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "discrete-painting",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "southern-disaster",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aging-niagara",
   "metadata": {},
   "source": [
    "##  Step4. 결과 분석과 결론 제시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-extension",
   "metadata": {},
   "source": [
    "### Tesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-collect",
   "metadata": {},
   "outputs": [],
   "source": [
    "recognize_images(cropped_image_path_list[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "novel-freeze",
   "metadata": {},
   "source": [
    "### keras_ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-bangkok",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_ocr.tools.drawAnnotations(image=images_keras_ocr[7], \n",
    "                                    predictions=prediction_groups[7][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "measured-occurrence",
   "metadata": {},
   "source": [
    "### Google OCR API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cordless-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_text(images[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "arctic-seventh",
   "metadata": {},
   "source": [
    "##  Step5. 회고\n",
    "- OCR을 활용하여 구현하려는 서비스의 기획\n",
    "- 모델 평가기준 세우기\n",
    "- 평가기준에 따라 충분한 분량의 테스트가 진행되고 그 결과정리"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
