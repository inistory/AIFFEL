{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copy of E11.ipynb","provenance":[{"file_id":"1RF5p8eCOEks8wGgdUv9e08xe7sO8HZqB","timestamp":1636516920600}],"collapsed_sections":[],"mount_file_id":"1RF5p8eCOEks8wGgdUv9e08xe7sO8HZqB","authorship_tag":"ABX9TyPbw7rQEioWE20E7xrv87Kq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"CAcRXTElx6Yt","executionInfo":{"status":"ok","timestamp":1636513130356,"user_tz":-540,"elapsed":3656,"user":{"displayName":"김정인","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh3vkUnAYiRh4RDdp2el8MRY_E4lyJNoUMMOFlFlA=s64","userId":"11915939704307778496"}}},"source":["import re\n","import os\n","import pandas as pd\n","import numpy as np\n","import tensorflow as tf\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"jXjltAIpyHg7"},"source":["# 데이터 로드할 때 빠르게 로드할 수 있도록하는 설정 변수\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","# 데이터 ROOT 경로 변수\n","ROOT_PATH = '/content/drive/MyDrive/Github/AIFFEL/E11'\n","\n","# BATCH_SIZE 변수\n","BATCH_SIZE = 16\n","\n","# X-RAY 이미지 사이즈 변수\n","IMAGE_SIZE = [180, 180]\n","\n","# EPOCH 크기 변수\n","EPOCHS = 40"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8iyo5lFEyfOE"},"source":["train_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/data/train/*/*'))\n","test_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/data/test/*/*'))\n","val_filenames = tf.io.gfile.glob(str(ROOT_PATH + '/data/val/*/*'))\n","\n","print(len(train_filenames))\n","print(len(test_filenames))\n","print(len(val_filenames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w1rrv-6rzwWA"},"source":["filenames = tf.io.gfile.glob(str(ROOT_PATH + '/chest_xray/train/*/*'))\n","filenames.extend(tf.io.gfile.glob(str(ROOT_PATH + '/chest_xray/val/*/*')))\n","\n","train_filenames, val_filenames = train_test_split(filenames, test_size=0.2)\n","\n","print(len(train_filenames))\n","print(len(val_filenames))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBzRnusvzwRP"},"source":["COUNT_NORMAL = len([filename for filename in train_filenames if \"NORMAL\" in filename])\n","print(\"Normal images count in training set: \" + str(COUNT_NORMAL))\n","\n","COUNT_PNEUMONIA = len([filename for filename in train_filenames if \"PNEUMONIA\" in filename])\n","print(\"Pneumonia images count in training set: \" + str(COUNT_PNEUMONIA))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"POqrRq8BzwLk"},"source":["train_list_ds = tf.data.Dataset.from_tensor_slices(train_filenames)\n","val_list_ds = tf.data.Dataset.from_tensor_slices(val_filenames)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z7rRQhjLzwDw"},"source":["TRAIN_IMG_COUNT = tf.data.experimental.cardinality(train_list_ds).numpy()\n","print(\"Training images count: \" + str(TRAIN_IMG_COUNT))\n","\n","VAL_IMG_COUNT = tf.data.experimental.cardinality(val_list_ds).numpy()\n","print(\"Validating images count: \" + str(VAL_IMG_COUNT))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0SSt_MOrzv-l"},"source":["CLASS_NAMES = np.array([str(tf.strings.split(item, os.path.sep)[-1].numpy())[2:-1]\n","                        for item in tf.io.gfile.glob(str(ROOT_PATH + \"/chest_xray/train/*\"))])\n","print(CLASS_NAMES)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1rW6ij8xzv6m"},"source":["def get_label(file_path):\n","    parts = tf.strings.split(file_path, os.path.sep)\n","    return parts[-2] == \"PNEUMONIA\"   # 폐렴이면 양성(True), 노말이면 음성(False)를 리턴하게 합니다."],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8NYiV6uJzv2p"},"source":["def decode_img(img):\n","  # 이미지를 uint8 tensor로 바꾼다.\n","  img = tf.image.decode_jpeg(img, channels=3)\n","  # img를 범위 [0,1]의 float32 데이터 타입으로 바꾼다.\n","  img = tf.image.convert_image_dtype(img, tf.float32)\n","  # img의 이미지 사이즈를 IMAGE_SIZE에서 지정한 사이즈로 수정한다.\n","  return tf.image.resize(img, IMAGE_SIZE)\n","\n","def process_path(file_path):\n","    label = get_label(file_path)\n","    img = tf.io.read_file(file_path)\n","    img = decode_img(img)\n","    return img, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"t3gJE76_zvqX"},"source":["train_ds = train_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n","val_ds = val_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2u95Yr8Pzvd6"},"source":["for image, label in train_ds.take(1):\n","    print(\"Image shape: \", image.numpy().shape)\n","    print(\"Label: \", label.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rAd1nyjMzvae"},"source":["\n","test_list_ds = tf.data.Dataset.list_files(str(ROOT_PATH + '/data/test/*/*'))\n","TEST_IMAGE_COUNT = tf.data.experimental.cardinality(test_list_ds).numpy()\n","test_ds = test_list_ds.map(process_path, num_parallel_calls=AUTOTUNE)\n","test_ds = test_ds.batch(BATCH_SIZE)\n","\n","print(TEST_IMAGE_COUNT)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YByxCL32zvWL"},"source":["def prepare_for_training(ds, shuffle_buffer_size=1000):\n","\n","    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n","\n","    ds = ds.repeat()\n","\n","    ds = ds.batch(BATCH_SIZE)\n","\n","    ds = ds.prefetch(buffer_size=AUTOTUNE)\n","\n","    return ds\n","\n","train_ds_basic = prepare_for_training(train_ds)\n","val_ds_basic = prepare_for_training(val_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZGS5Oc20L1x"},"source":["def augment(image,label):\n","    image = tf.image.random_flip_left_right(image)  # 랜덤하게 좌우를 반전합니다.\n","    \n","    return image,label\n","\n","def prepare_for_training_aug(ds, shuffle_buffer_size=1000):\n","    # augment 적용 부분이 배치처리 함수에 추가되었습니다.\n","    ds = ds.map(\n","            augment,       # augment 함수 적용\n","            num_parallel_calls=2\n","        )\n","\n","    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n","\n","    ds = ds.repeat()\n","\n","    ds = ds.batch(BATCH_SIZE)\n","\n","    ds = ds.prefetch(buffer_size=AUTOTUNE)\n","\n","    return ds\n","\n","train_aug_ds = prepare_for_training_aug(train_ds)\n","val_aug_ds = prepare_for_training_aug(val_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6JWx6dDz0LyP"},"source":["image_batch, label_batch = next(iter(train_ds_basic))\n","\n","def show_batch(image_batch, label_batch):\n","    plt.figure(figsize=(10,10))\n","    print(image_batch.shape)\n","    print(label_batch.shape)\n","    for n in range(16):\n","        ax = plt.subplot(5,5,n+1)\n","        plt.imshow(image_batch[n])\n","        if label_batch[n]:\n","            plt.title(\"PNEUMONIA\")\n","        else:\n","            plt.title(\"NORMAL\")\n","        plt.axis(\"off\")\n","\n","show_batch(image_batch.numpy(), label_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WS-7i0e50LvP"},"source":["image_aug_batch, label_aug_batch = next(iter(train_aug_ds))\n","\n","def show_batch(image_batch, label_batch):\n","    plt.figure(figsize=(10,10))\n","    print(image_batch.shape)\n","    print(label_batch.shape)\n","    for n in range(16):\n","        ax = plt.subplot(5,5,n+1)\n","        plt.imshow(image_batch[n])\n","        if label_batch[n]:\n","            plt.title(\"PNEUMONIA\")\n","        else:\n","            plt.title(\"NORMAL\")\n","        plt.axis(\"off\")\n","\n","show_batch(image_aug_batch.numpy(), label_aug_batch.numpy())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"--DmW4YJ0Ls5"},"source":["def conv_block(layer, filters):\n","    x = tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same')(layer)\n","    x = tf.keras.layers.SeparableConv2D(filters, 3, activation='relu', padding='same')(x)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    x = tf.keras.layers.MaxPool2D()(x)\n","\n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GCrSbMHu0LqH"},"source":["def dense_block(layer, units, dropout_rate=0.5, dropout=True):\n","    x = tf.keras.layers.Dense(units, activation='relu')(layer)\n","    x = tf.keras.layers.BatchNormalization()(x)\n","    if dropout:\n","        x = tf.keras.layers.Dropout(dropout_rate)(x)\n","    \n","    return x"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XDgf5X8U0Lmo"},"source":["def build_model(dropout=True):\n","    input_layer = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n","    \n","    x = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(input_layer)\n","    x = tf.keras.layers.Conv2D(16, 3, activation='relu', padding='same')(x)\n","    x = tf.keras.layers.MaxPool2D()(x)\n","    \n","    x = conv_block(x, 32)\n","    x = conv_block(x, 64)\n","    \n","    x = conv_block(x, 128)\n","    if dropout:\n","        x = tf.keras.layers.Dropout(0.2)(x)\n","    \n","    x = conv_block(x, 256)\n","    if dropout:\n","        x = tf.keras.layers.Dropout(0.2)(x)\n","    \n","    x = tf.keras.layers.Flatten()(x)\n","    x = dense_block(x, 512, 0.7)\n","    x = dense_block(x, 128, 0.5)\n","    x = dense_block(x, 64, 0.3)\n","    \n","    output = tf.keras.layers.Dense(1, activation='sigmoid')(x)\n","    \n","    model = tf.keras.Model(inputs=input_layer, outputs=output)\n","    \n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1c39dXA60Ljp"},"source":["weight_for_0 = (1 / COUNT_NORMAL)*(TRAIN_IMG_COUNT)/2.0 \n","weight_for_1 = (1 / COUNT_PNEUMONIA)*(TRAIN_IMG_COUNT)/2.0\n","\n","class_weight = {0: weight_for_0, 1: weight_for_1}\n","\n","print('Weight for class 0: {:.2f}'.format(weight_for_0))\n","print('Weight for class 1: {:.2f}'.format(weight_for_1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8VBdNCMc0Lg2"},"source":["with tf.device('/GPU:0'):\n","    model = build_model()\n","\n","    METRICS = [\n","        'accuracy',\n","        tf.keras.metrics.Precision(name='precision'),\n","        tf.keras.metrics.Recall(name='recall')\n","    ]\n","    \n","    model.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n","        loss='binary_crossentropy',\n","        metrics=METRICS\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nW-dK-pu0XRA"},"source":["with tf.device('/GPU:0'):\n","    history = model.fit(\n","        train_ds_basic,\n","        steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n","        epochs=EPOCHS,\n","        validation_data=val_ds_basic,\n","        validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n","        class_weight=class_weight,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uu_mbd870XNw"},"source":["with tf.device('/GPU:0'):\n","    model_aug = build_model()\n","\n","    METRICS = [\n","        'accuracy',\n","        tf.keras.metrics.Precision(name='precision'),\n","        tf.keras.metrics.Recall(name='recall')\n","    ]\n","    \n","    model_aug.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n","        loss='binary_crossentropy',\n","        metrics=METRICS\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"j4LGt2pL0XJw"},"source":["\n","with tf.device('/GPU:0'):\n","    history_aug = model_aug.fit(\n","        train_aug_ds,\n","        steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n","        epochs=EPOCHS,\n","        validation_data=val_aug_ds,\n","        validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n","        class_weight=class_weight,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"niTU5wC20XHq"},"source":["with tf.device('/GPU:0'):\n","    model_no_drop = build_model(dropout=False)\n","\n","    METRICS = [\n","        'accuracy',\n","        tf.keras.metrics.Precision(name='precision'),\n","        tf.keras.metrics.Recall(name='recall')\n","    ]\n","    \n","    model_no_drop.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n","        loss='binary_crossentropy',\n","        metrics=METRICS\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wUzxF3Ft0XD7"},"source":["\n","with tf.device('/GPU:0'):\n","    history_no_drop = model_no_drop.fit(\n","        train_ds_basic,\n","        steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n","        epochs=EPOCHS,\n","        validation_data=val_ds_basic,\n","        validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n","        class_weight=class_weight,\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Uh9J0KgU0XAc"},"source":["lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(factor=0.7, monitor='val_loss', patience=1, verbose=2, min_lr=1e-8)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odYfHoYG0hbA"},"source":["with tf.device('/GPU:0'):\n","    model_no_drop_lr = build_model(dropout=False)\n","\n","    METRICS = [\n","        'accuracy',\n","        tf.keras.metrics.Precision(name='precision'),\n","        tf.keras.metrics.Recall(name='recall')\n","    ]\n","    \n","    model_no_drop_lr.compile(\n","        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999),\n","        loss='binary_crossentropy',\n","        metrics=METRICS\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"KkwnUODx0hV1"},"source":["\n","with tf.device('/GPU:0'):\n","    history_no_drop_lr = model_no_drop_lr.fit(\n","        train_ds_basic,\n","        steps_per_epoch=TRAIN_IMG_COUNT // BATCH_SIZE,\n","        epochs=EPOCHS,\n","        validation_data=val_ds_basic,\n","        validation_steps=VAL_IMG_COUNT // BATCH_SIZE,\n","        class_weight=class_weight,\n","        callbacks=[lr_scheduler],\n","    )"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fr3z_y8b0hRD"},"source":["loss, acc, prec, rec = model.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IkQXq1EN0hNi"},"source":["loss, acc, prec, rec = model_aug.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"W8MzyD1K0hJG"},"source":["loss, acc, prec, rec = model_no_drop.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"86etErAC0hG3"},"source":["loss, acc, prec, rec = model_no_drop_lr.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Up14OhX70hAe"},"source":["fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n","ax = ax.ravel()\n","\n","for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n","    ax[i].plot(history.history[met])\n","    ax[i].plot(history.history['val_' + met])\n","    ax[i].plot(history_aug.history[met])\n","    ax[i].plot(history_aug.history['val_' + met])\n","    ax[i].set_title('Model {}'.format(met))\n","    ax[i].set_xlabel('epochs')\n","    ax[i].set_ylabel(met)\n","    ax[i].legend(['basic_train', 'basic_val', 'aug_train', 'aug_val'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PUG26COt0qDY"},"source":["fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n","ax = ax.ravel()\n","\n","for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n","    ax[i].plot(history_aug.history[met])\n","    ax[i].plot(history_aug.history['val_' + met])\n","    ax[i].plot(history_no_drop.history[met])\n","    ax[i].plot(history_no_drop.history['val_' + met])\n","    ax[i].set_title('Model {}'.format(met))\n","    ax[i].set_xlabel('epochs')\n","    ax[i].set_ylabel(met)\n","    ax[i].legend(['aug_train', 'aug_val','no_drop_train', 'no_drop_val'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YHXF67wo0p9m"},"source":["fig, ax = plt.subplots(1, 4, figsize=(20, 3))\n","ax = ax.ravel()\n","\n","for i, met in enumerate(['precision', 'recall', 'accuracy', 'loss']):\n","    ax[i].plot(history_no_drop.history[met])\n","    ax[i].plot(history_no_drop.history['val_' + met])\n","    ax[i].plot(history_no_drop_lr.history[met])\n","    ax[i].plot(history_no_drop_lr.history['val_' + met])\n","    ax[i].set_title('Model {}'.format(met))\n","    ax[i].set_xlabel('epochs')\n","    ax[i].set_ylabel(met)\n","    ax[i].legend(['no_drop_train', 'no_drop_val', 'lr_train', 'lr_val',])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oUE20TR10p4S"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DOIec_-O0p1s"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eYACkF7Z0pzD"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gY7MlRmG0pvx"},"source":[""],"execution_count":null,"outputs":[]}]}